name: Auto-Generate Fixture Analysis

on:
  # 1. Scheduled run: Check every day at 04:00 UTC (adjust to fit your needs)
  schedule:
    - cron: '40 0 * * *'
  # 2. Manual run (for development/testing)
  workflow_dispatch:
  # 3. Runs on push (optional, good for testing logic changes)
  push:
    branches: [ "main" ]
    paths:
      - 'src/**.py'
      - '*.py'
      - '.github/workflows/main_run.yml' # Reruns if workflow logic changes

jobs:
  run_analysis_with_retry:
    runs-on: ubuntu-latest
    permissions:
      contents: write # Needed for git-auto-commit-action

    # -------------------------------------------------------------
    # üö® RETRY STRATEGY
    # The entire job will retry up to 3 times if any step fails (e.g., API timeouts).
    # This is excellent for handling temporary data collection failures.
    # -------------------------------------------------------------
    strategy:
      fail-fast: false
      matrix: # <--- as indented incorrectly relative to 'strategy'
        os: [ ubuntu-latest ]
        python-version: [ '3.11' ]

    steps:
      - name: ‚¨áÔ∏è Checkout code
        uses: actions/checkout@v4

      - name: üõ†Ô∏è Set up Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.11' # Ensure this matches your project version

      - name: üì¶ Install Python Dependencies
        run: |
          python -m pip install --upgrade pip
          # Check for requirements.txt and install all necessary libraries (requests, pandas, etc.)
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install requests pandas tabulate
          fi

      # -------------------------------------------------------------
      # ‚è∞ DATE CHECK LOGIC
      # Determines if 24 hours have passed since the last successful run.
      # -------------------------------------------------------------
      - name: ‚è≥ Check Next Run Condition
        id: check_time
        # Set RUN_ANALYSIS=true by default for the very first run
        env:
          RUN_ANALYSIS: true
        run: |
          # 1. Define the file path for the next fixture date (must be generated by main.py)
          FIXTURE_DATE_FILE="data/next_fixture_date.log"
          
          # 2. Check if the next fixture date file exists (meaning the main script ran successfully before)
          if [ -f $FIXTURE_DATE_FILE ]; then
              # Read the date of the NEXT upcoming fixture (e.g., 2025-12-20)
              NEXT_FIXTURE_DATE=$(cat $FIXTURE_DATE_FILE | xargs)
          
              # Get today's date in YYYY-MM-DD format
              CURRENT_DATE=$(date +%Y-%m-%d)
          
              # Calculate the target run date: 24 hours AFTER the next fixture date
              # Note: We assume the analysis is needed *after* the fixture date has passed.
              # Use GNU date command for date arithmetic (common on GitHub runners)
              TARGET_RUN_DATE=$(date -d "$NEXT_FIXTURE_DATE + 1 day" +%Y-%m-%d)
          
              echo "Next Fixture Date: $NEXT_FIXTURE_DATE"
              echo "Target Run Date (24h after fixture): $TARGET_RUN_DATE"
              echo "Current Date: $CURRENT_DATE"
          
              # 3. Decision Logic: Only run if TODAY is the TARGET_RUN_DATE or later.
              # This ensures the analysis runs only after the latest set of fixtures has completed.
              if [[ "$CURRENT_DATE" > "$TARGET_RUN_DATE" ]]; then         
                  echo "::notice:: Target date ($TARGET_RUN_DATE) reached. Proceeding with analysis."
                  echo "RUN_ANALYSIS=true" >> $GITHUB_ENV
              else
                  echo "::notice:: Fixtures are not complete or next fixture is far away. Skipping run."
                  echo "RUN_ANALYSIS=false" >> $GITHUB_ENV
              fi
          
          else
              # If the file doesn't exist, this is the very first run or a file cleanup was missed.
              echo "::warning:: Next fixture date file not found. Assuming first run. Proceeding with analysis."
              # This ensures the script runs the first time to generate the file.
              echo "RUN_ANALYSIS=true" >> $GITHUB_ENV
          fi

      # -------------------------------------------------------------
      # üìù GENERATE ANALYSIS
      # This entire block only runs if RUN_ANALYSIS is true
      # -------------------------------------------------------------
      - name: üìù Generate New Documentation Content
        # The 'if' condition makes this step (and subsequent steps) conditional
        if: env.RUN_ANALYSIS == 'true'
        id: run_generator
        # Execute the Python script
        run: |
          export PYTHONPATH=$PYTHONPATH:$(pwd)/src
          # Run generator 
          python main.py
          
          # üí° If the python script fails (e.g., due to API error), 
          # the entire job will restart due to the 'strategy: max-attempts: 3' setting.

      # -------------------------------------------------------------
      # üíæ LOG & COMMIT
      # Only runs after successful generation and logging of the new run time
      # -------------------------------------------------------------
      - name: üíæ Log New Successful Run Time
        if: success() && env.RUN_ANALYSIS == 'true'
        run: |
          # Overwrite the log file with the current Unix timestamp
          date +%s > data/last_successful_run.log

      - name: ‚¨ÜÔ∏è Commit and Push Final Documentation
        if: success() && env.RUN_ANALYSIS == 'true'
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "docs: Auto-update analysis and log time."
          files: |
            data/**